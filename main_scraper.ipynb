{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/chromedriver\r\n"
     ]
    }
   ],
   "source": [
    "!which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **ex_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting urls \n",
    "lol_champs_url = \"https://na.leagueoflegends.com/en-us/champions/\"\n",
    "lol_graphs_url = \"https://www.leagueofgraphs.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visiting main lol champs\n",
    "browser.visit(lol_champs_url)\n",
    "\n",
    "# creating soup of champs html\n",
    "lol_champs_html = browser.html\n",
    "lol_champs_soup = bs(lol_champs_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aatrox',\n",
       " 'ahri',\n",
       " 'akali',\n",
       " 'alistar',\n",
       " 'amumu',\n",
       " 'anivia',\n",
       " 'annie',\n",
       " 'aphelios',\n",
       " 'ashe',\n",
       " 'aurelion sol',\n",
       " 'azir',\n",
       " 'bard',\n",
       " 'blitzcrank',\n",
       " 'brand',\n",
       " 'braum',\n",
       " 'caitlyn',\n",
       " 'camille',\n",
       " 'cassiopeia',\n",
       " \"cho'gath\",\n",
       " 'corki',\n",
       " 'darius',\n",
       " 'diana',\n",
       " 'dr. mundo',\n",
       " 'draven',\n",
       " 'ekko',\n",
       " 'elise',\n",
       " 'evelynn',\n",
       " 'ezreal',\n",
       " 'fiddlesticks',\n",
       " 'fiora',\n",
       " 'fizz',\n",
       " 'galio',\n",
       " 'gangplank',\n",
       " 'garen',\n",
       " 'gnar',\n",
       " 'gragas',\n",
       " 'graves',\n",
       " 'hecarim',\n",
       " 'heimerdinger',\n",
       " 'illaoi',\n",
       " 'irelia',\n",
       " 'ivern',\n",
       " 'janna',\n",
       " 'jarvan iv',\n",
       " 'jax',\n",
       " 'jayce',\n",
       " 'jhin',\n",
       " 'jinx',\n",
       " \"kai'sa\",\n",
       " 'kalista',\n",
       " 'karma',\n",
       " 'karthus',\n",
       " 'kassadin',\n",
       " 'katarina',\n",
       " 'kayle',\n",
       " 'kayn',\n",
       " 'kennen',\n",
       " \"kha'zix\",\n",
       " 'kindred',\n",
       " 'kled',\n",
       " \"kog'maw\",\n",
       " 'leblanc',\n",
       " 'lee sin',\n",
       " 'leona',\n",
       " 'lillia',\n",
       " 'lissandra',\n",
       " 'lucian',\n",
       " 'lulu',\n",
       " 'lux',\n",
       " 'malphite',\n",
       " 'malzahar',\n",
       " 'maokai',\n",
       " 'master yi',\n",
       " 'miss fortune',\n",
       " 'mordekaiser',\n",
       " 'morgana',\n",
       " 'nami',\n",
       " 'nasus',\n",
       " 'nautilus',\n",
       " 'neeko',\n",
       " 'nidalee',\n",
       " 'nocturne',\n",
       " 'nunu & willump',\n",
       " 'olaf',\n",
       " 'orianna',\n",
       " 'ornn',\n",
       " 'pantheon',\n",
       " 'poppy',\n",
       " 'pyke',\n",
       " 'qiyana',\n",
       " 'quinn',\n",
       " 'rakan',\n",
       " 'rammus',\n",
       " \"rek'sai\",\n",
       " 'renekton',\n",
       " 'rengar',\n",
       " 'riven',\n",
       " 'rumble',\n",
       " 'ryze',\n",
       " 'samira',\n",
       " 'sejuani',\n",
       " 'senna',\n",
       " 'seraphine',\n",
       " 'sett',\n",
       " 'shaco',\n",
       " 'shen',\n",
       " 'shyvana',\n",
       " 'singed',\n",
       " 'sion',\n",
       " 'sivir',\n",
       " 'skarner',\n",
       " 'sona',\n",
       " 'soraka',\n",
       " 'swain',\n",
       " 'sylas',\n",
       " 'syndra',\n",
       " 'tahm kench',\n",
       " 'taliyah',\n",
       " 'talon',\n",
       " 'taric',\n",
       " 'teemo',\n",
       " 'thresh',\n",
       " 'tristana',\n",
       " 'trundle',\n",
       " 'tryndamere',\n",
       " 'twisted fate',\n",
       " 'twitch',\n",
       " 'udyr',\n",
       " 'urgot',\n",
       " 'varus',\n",
       " 'vayne',\n",
       " 'veigar',\n",
       " \"vel'koz\",\n",
       " 'vi',\n",
       " 'viktor',\n",
       " 'vladimir',\n",
       " 'volibear',\n",
       " 'warwick',\n",
       " 'wukong',\n",
       " 'xayah',\n",
       " 'xerath',\n",
       " 'xin zhao',\n",
       " 'yasuo',\n",
       " 'yone',\n",
       " 'yorick',\n",
       " 'yuumi',\n",
       " 'zac',\n",
       " 'zed',\n",
       " 'ziggs',\n",
       " 'zilean',\n",
       " 'zoe',\n",
       " 'zyra']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting champions section\n",
    "lol_champs_results = lol_champs_soup.find(\"section\", class_=\"style__Wrapper-ntddd-0 style__ResponsiveWrapper-ntddd-4 fSyoAt\")\n",
    "\n",
    "# list to hold champion names\n",
    "champion_list = []\n",
    "# getting individual champs. Looping through results and appending names to champion_list\n",
    "names = lol_champs_results.find_all(\"span\", class_='style__Text-sc-12h96bu-3 gPUACV')\n",
    "for champ in names:\n",
    "    champion_name = champ.text.lower()\n",
    "    champion_list.append(champion_name)\n",
    "\n",
    "champion_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_list = [\"Aatrox\"]\n",
    "\n",
    "# list to hold champion dictionaries\n",
    "champion_dict_list = []\n",
    "\n",
    "for i in range(len(practice_list)):\n",
    "    # going to each champions page, souping html\n",
    "    browser.visit(f\"{lol_champs_url}/{practice_list[i].lower()}\")\n",
    "    champ_html = browser.html\n",
    "    champ_soup = bs(champ_html, 'html.parser')\n",
    "    \n",
    "    # getting champions role, difficulty\n",
    "    role_difficulty_results = champ_soup.find_all(\"div\", class_=\"style__SpecsItemValue-sc-1o884zt-15 ieHviE\")\n",
    "    role = practice_resuls[0].text\n",
    "    difficulty = practice_resuls[1].text\n",
    "    \n",
    "    # getting moves\n",
    "    moves = champ_soup.find_all(\"h5\", class_=\"style__AbilityInfoItemName-ulelzu-10 cjXBRP\")\n",
    "    passive_move = moves[0].text\n",
    "    q_move = moves[1].text\n",
    "    w_move = moves[2].text\n",
    "    e_move = moves[3].text\n",
    "    r_move = moves[4].text\n",
    "    \n",
    "    # going to lol_graphs to get map role\n",
    "    browser.visit(f\"{lol_graphs_url}/champions/builds/{practice_list[i].lower()}\")\n",
    "    lol_graphs_html = browser.html\n",
    "    lol_graph_soup = bs(lol_graphs_html)\n",
    "    \n",
    "    map_role = lol_graph_soup.find(\"div\", class_=\"bannerSubtitle\")\n",
    "    champ_map_role = map_role.get_text(strip=True)\n",
    "    \n",
    "    # creating champions intro dict (name,role,map role, difficulty)\n",
    "    champ_intro_dict = {\n",
    "        \"Champion Name\": practice_list[i],\n",
    "        \"Role\": role,\n",
    "        \"Difficulty\": difficulty,\n",
    "        \"Map Role\": champ_map_role\n",
    "    }\n",
    "    \n",
    "    # appending champ_dict to champion_dict_list\n",
    "    champion_dict_list.append(champ_intro_dict)\n",
    "    \n",
    "    # creating champion_moves_dict\n",
    "    champ_moves_dict = {\n",
    "        \"Champion Name\": practice_list[i],\n",
    "        \"Passive\": passive_move, \n",
    "        \"Q\": q_move, \n",
    "        \"W\": w_move, \n",
    "        \"E\": e_move, \n",
    "        \"R\": r_move\n",
    "    }\n",
    "    \n",
    "    # appending champ_moves to champion_dict_list\n",
    "    champion_dict_list.append(champ_moves_dict)\n",
    "    \n",
    "#     print(practice_list[i], role, difficulty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Champion Name': 'Aatrox', 'Role': 'Fighter', 'Difficulty': 'Moderate'}\n",
      "{'Champion Name': 'Aatrox', 'Passive': 'Deathbringer Stance', 'Q': 'The Darkin Blade', 'W': 'Infernal Chains', 'E': 'Umbral Dash', 'R': 'World Ender'}\n"
     ]
    }
   ],
   "source": [
    "for x in champion_dict_list:\n",
    "    print(x)\n",
    "\n",
    "# champ_df = pd.DataFrame(champion_dict_list)\n",
    "# champ_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Top'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.visit(f\"{lol_graphs_url}/champions/builds/{practice_list[i].lower()}\")\n",
    "lol_graphs_html = browser.html\n",
    "lol_graph_soup = bs(lol_graphs_html)\n",
    "\n",
    "map_role = lol_graph_soup.find(\"div\", class_=\"bannerSubtitle\")\n",
    "map_role.get_text(strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lol_env]",
   "language": "python",
   "name": "conda-env-lol_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
